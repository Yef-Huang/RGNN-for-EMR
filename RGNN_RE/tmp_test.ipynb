{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "# import scipy.io as scio\n",
    "import hdf5storage as hdf5\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import os,re\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.data import Data\n",
    "from module import rgnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sub_1 (2025, 62, 25) (2025, 3)\n",
      "sub_2 (2025, 62, 25) (2025, 3)\n",
      "sub_3 (2025, 62, 25) (2025, 3)\n",
      "sub_4 (2025, 62, 25) (2025, 3)\n",
      "sub_5 (2025, 62, 25) (2025, 3)\n",
      "sub_6 (2025, 62, 25) (2025, 3)\n",
      "sub_7 (2025, 62, 25) (2025, 3)\n",
      "sub_8 (2025, 62, 25) (2025, 3)\n",
      "sub_9 (2025, 62, 25) (2025, 3)\n",
      "sub_10 (2025, 62, 25) (2025, 3)\n",
      "sub_11 (2025, 62, 25) (2025, 3)\n",
      "sub_12 (2025, 62, 25) (2025, 3)\n",
      "sub_13 (2025, 62, 25) (2025, 3)\n",
      "sub_14 (2025, 62, 25) (2025, 3)\n",
      "sub_15 (2025, 62, 25) (2025, 3)\n",
      "[[0.  0.4 0.6]\n",
      " [0.  0.4 0.6]\n",
      " [0.  0.4 0.6]\n",
      " ...\n",
      " [0.6 0.4 0. ]\n",
      " [0.6 0.4 0. ]\n",
      " [0.6 0.4 0. ]]\n"
     ]
    }
   ],
   "source": [
    "def EmotionDL(label,noise = 0.6):\n",
    "    if label == 0:\n",
    "        new_label = [1 - 2 * noise / 3, 2 * noise / 3, 0]\n",
    "    elif label == 1:\n",
    "        new_label = [noise / 3, 1 - 2 * noise / 3, noise / 3]\n",
    "    elif label == 2:\n",
    "        new_label = [0, 2 * noise / 3, 1 - 2 * noise / 3]\n",
    "    return new_label\n",
    "def extend_normal(sample):\n",
    "    for i in range(len(sample)):\n",
    "        features_min = np.min(sample[i])\n",
    "        features_max = np.max(sample[i])\n",
    "        sample[i] = (sample[i] - features_min) / (features_max - features_min)\n",
    "    return sample\n",
    "\n",
    "seed_path = 'seed_processed'\n",
    "data_path = os.path.join(seed_path, 'dic_all_subjects.mat')\n",
    "label_path = os.path.join(seed_path, 'dic_all_subjects_label.mat')\n",
    "data_dic = hdf5.loadmat(data_path)\n",
    "label_dic = hdf5.loadmat(label_path)\n",
    "for key in data_dic.keys():\n",
    "    if key.startswith('__'):\n",
    "        continue\n",
    "    data_dic[key] = extend_normal(data_dic[key]) # 归一化; 2025*62*5\n",
    "    label_dic[key] = np.array([EmotionDL(label) for label in label_dic[key][0]]) # 1*2025 -> 2025*3\n",
    "    print(key, data_dic[key].shape, label_dic[key].shape)\n",
    "\n",
    "print(label_dic[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sub_13 for test sub\n",
      "train sub list: ['sub_1', 'sub_2', 'sub_3', 'sub_4', 'sub_5', 'sub_6', 'sub_7', 'sub_8', 'sub_9', 'sub_10', 'sub_11', 'sub_12', 'sub_14', 'sub_15']\n",
      "x_train:(28350, 62, 25),  y_train:(28350, 3),  x_test:(2025, 62, 25),  y_test:(2025, 3)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'edge_index' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 65\u001b[0m\n\u001b[0;32m     62\u001b[0m sub \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m13\u001b[39m \u001b[38;5;66;03m# 1-15\u001b[39;00m\n\u001b[0;32m     64\u001b[0m sub_list \u001b[38;5;241m=\u001b[39m [i \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m16\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m!=\u001b[39m sub]\n\u001b[1;32m---> 65\u001b[0m train_data_list, test_data_list \u001b[38;5;241m=\u001b[39m \u001b[43msub_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_dic\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_dic\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msub\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msub_list\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(train_data_list), \u001b[38;5;28mlen\u001b[39m(test_data_list))\n\u001b[0;32m     68\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m128\u001b[39m\n",
      "Cell \u001b[1;32mIn[10], line 53\u001b[0m, in \u001b[0;36msub_split\u001b[1;34m(data_dict, label_dict, sub_test, sub_train)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx_train:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx_train\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,  y_train:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00my_train\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,  x_test:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx_test\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,  y_test:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00my_test\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(x_train)):\n\u001b[1;32m---> 53\u001b[0m     train_data_list\u001b[38;5;241m.\u001b[39mappend(Data(x\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfrom_numpy(x_train[i])\u001b[38;5;241m.\u001b[39mfloat(), edge_index\u001b[38;5;241m=\u001b[39m\u001b[43medge_index\u001b[49m, edge_attr\u001b[38;5;241m=\u001b[39medge_weight, y\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mTensor(y_train[i])))\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(x_test)):\n\u001b[0;32m     55\u001b[0m     test_data_list\u001b[38;5;241m.\u001b[39mappend(Data(x\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfrom_numpy(x_test[i])\u001b[38;5;241m.\u001b[39mfloat(), edge_index\u001b[38;5;241m=\u001b[39medge_index, edge_attr\u001b[38;5;241m=\u001b[39medge_weight, y\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mTensor(y_test[i])))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'edge_index' is not defined"
     ]
    }
   ],
   "source": [
    "def sub_split(data_dict, label_dict, sub_test, sub_train=None):\n",
    "    \n",
    "    if sub_test not in range(1, 16):\n",
    "        raise ValueError('sub for test must be in range(1, 16)')\n",
    "    if sub_train is not None:\n",
    "        if all(1 <= x <= 16 for x in sub_train)==False:\n",
    "            raise ValueError('sub for train must be in range(1, 16)')\n",
    "        if sub_test in sub_train:\n",
    "            raise ValueError('sub for test and train can not overlap')\n",
    "    \n",
    "    x_train =[]\n",
    "    y_train = []\n",
    "    x_test =None\n",
    "    y_test = None\n",
    "    train_data_list = []\n",
    "    test_data_list = [] \n",
    "    train_sub_list = [] # 训练集的被试列表\n",
    "    for i in range(1, 16):\n",
    "        for key in data_dict.keys():\n",
    "            if key.startswith('__'): continue\n",
    "            sub_num = int(key.split('_')[1])\n",
    "            if sub_num != i: continue\n",
    "            # print('shape:', key, data_dict[key].shape, label_dict[key].shape)\n",
    "            if sub_num != sub_test:\n",
    "                if sub_train is not None:\n",
    "                    if sub_num in sub_train:\n",
    "                        x_train.append(data_dict[key])\n",
    "                        y_train.append(label_dict[key])\n",
    "                        train_sub_list.append(key)\n",
    "                    else: pass\n",
    "                else:\n",
    "                    x_train.append(data_dict[key])\n",
    "                    y_train.append(label_dict[key])\n",
    "                    train_sub_list.append(key)\n",
    "            else:\n",
    "                print('{} for test sub'.format(key))\n",
    "                x_test = data_dict[key]\n",
    "                y_test = label_dict[key]\n",
    "    print('train sub list:', train_sub_list)\n",
    "    \n",
    "    x_train = np.asarray(x_train)\n",
    "    y_train = np.asarray(y_train) \n",
    "    x_test = np.asarray(x_test)\n",
    "    y_test = np.asarray(y_test)\n",
    "    \n",
    "    x_train = x_train.reshape(-1, x_train.shape[-2], x_train.shape[-1])\n",
    "    y_train = y_train.reshape(-1,y_train.shape[-1])\n",
    "    x_test = x_test.reshape(-1, x_test.shape[-2], x_test.shape[-1])\n",
    "    y_test = y_test.reshape(-1,y_test.shape[-1])\n",
    "    print(f'x_train:{x_train.shape},  y_train:{y_train.shape},  x_test:{x_test.shape},  y_test:{y_test.shape}')\n",
    "    \n",
    "    for i in range(len(x_train)):\n",
    "        train_data_list.append(Data(x=torch.from_numpy(x_train[i]).float(), edge_index=edge_index, edge_attr=edge_weight, y=torch.Tensor(y_train[i])))\n",
    "    for i in range(len(x_test)):\n",
    "        test_data_list.append(Data(x=torch.from_numpy(x_test[i]).float(), edge_index=edge_index, edge_attr=edge_weight, y=torch.Tensor(y_test[i])))\n",
    "    \n",
    "    assert(len(train_data_list)==x_train.shape[0] and len(train_data_list)==y_train.shape[0])\n",
    "    assert(len(test_data_list)==x_test.shape[0] and len(test_data_list)==y_test.shape[0])\n",
    "    \n",
    "    return train_data_list, test_data_list\n",
    "    \n",
    "sub = 13 # 1-15\n",
    "    \n",
    "sub_list = [i for i in range(1, 16) if i != sub]\n",
    "train_data_list, test_data_list = sub_split(data_dic, label_dic, sub, sub_list)\n",
    "print(len(train_data_list), len(test_data_list))\n",
    "\n",
    "batch_size = 128\n",
    "train_loader = DataLoader(train_data_list, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_data_list, batch_size=batch_size)\n",
    "for batch_data in train_loader:\n",
    "    print('batch data in trainer:')\n",
    "    print(batch_data)\n",
    "    break\n",
    "for batch_data in test_loader:\n",
    "    print('batch data in tester:')\n",
    "    print(batch_data)\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch18py38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
